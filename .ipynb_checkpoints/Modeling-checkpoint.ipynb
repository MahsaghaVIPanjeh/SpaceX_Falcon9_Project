{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c04b4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5daffa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_features = pd.read_csv('Falcon9_Dataset_Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6225b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_target = pd.read_csv('Falcon9_Dataset_Part2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12039a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(dataset_target['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6687474b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "267d61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "339f3120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset to train and test set\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9910020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 80)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2db177e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 80)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3af22242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b42d99a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17e3b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12315e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.50it/s]\n"
     ]
    }
   ],
   "source": [
    "#train all models with lazypredict to see which model is best the we can improve that\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models,predictions = clf.fit(X_train,X_test,Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3974ec2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "LGBMClassifier                     0.94               0.92     0.92      0.94   \n",
      "RidgeClassifier                    0.94               0.92     0.92      0.94   \n",
      "BernoulliNB                        0.94               0.92     0.92      0.94   \n",
      "XGBClassifier                      0.89               0.83     0.83      0.88   \n",
      "NearestCentroid                    0.78               0.79     0.79      0.78   \n",
      "LabelSpreading                     0.78               0.79     0.79      0.78   \n",
      "LabelPropagation                   0.78               0.79     0.79      0.78   \n",
      "GaussianNB                         0.78               0.79     0.79      0.78   \n",
      "LinearDiscriminantAnalysis         0.83               0.79     0.79      0.83   \n",
      "Perceptron                         0.83               0.75     0.75      0.81   \n",
      "ExtraTreesClassifier               0.83               0.75     0.75      0.81   \n",
      "RidgeClassifierCV                  0.83               0.75     0.75      0.81   \n",
      "SGDClassifier                      0.83               0.75     0.75      0.81   \n",
      "BaggingClassifier                  0.83               0.75     0.75      0.81   \n",
      "LogisticRegression                 0.83               0.75     0.75      0.81   \n",
      "RandomForestClassifier             0.83               0.75     0.75      0.81   \n",
      "SVC                                0.78               0.71     0.71      0.76   \n",
      "AdaBoostClassifier                 0.78               0.71     0.71      0.76   \n",
      "NuSVC                              0.78               0.71     0.71      0.76   \n",
      "ExtraTreeClassifier                0.78               0.71     0.71      0.76   \n",
      "PassiveAggressiveClassifier        0.72               0.67     0.67      0.72   \n",
      "QuadraticDiscriminantAnalysis      0.61               0.67     0.67      0.62   \n",
      "DecisionTreeClassifier             0.67               0.62     0.62      0.67   \n",
      "LinearSVC                          0.67               0.62     0.62      0.67   \n",
      "CalibratedClassifierCV             0.72               0.58     0.58      0.65   \n",
      "KNeighborsClassifier               0.67               0.50     0.50      0.53   \n",
      "DummyClassifier                    0.67               0.50     0.50      0.53   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "LGBMClassifier                       0.03  \n",
      "RidgeClassifier                      0.01  \n",
      "BernoulliNB                          0.02  \n",
      "XGBClassifier                        0.07  \n",
      "NearestCentroid                      0.01  \n",
      "LabelSpreading                       0.01  \n",
      "LabelPropagation                     0.01  \n",
      "GaussianNB                           0.01  \n",
      "LinearDiscriminantAnalysis           0.01  \n",
      "Perceptron                           0.01  \n",
      "ExtraTreesClassifier                 0.10  \n",
      "RidgeClassifierCV                    0.01  \n",
      "SGDClassifier                        0.01  \n",
      "BaggingClassifier                    0.02  \n",
      "LogisticRegression                   0.01  \n",
      "RandomForestClassifier               0.14  \n",
      "SVC                                  0.01  \n",
      "AdaBoostClassifier                   0.09  \n",
      "NuSVC                                0.01  \n",
      "ExtraTreeClassifier                  0.01  \n",
      "PassiveAggressiveClassifier          0.01  \n",
      "QuadraticDiscriminantAnalysis        0.01  \n",
      "DecisionTreeClassifier               0.01  \n",
      "LinearSVC                            0.01  \n",
      "CalibratedClassifierCV               0.03  \n",
      "KNeighborsClassifier                 0.01  \n",
      "DummyClassifier                      0.01  \n"
     ]
    }
   ],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f17dbd",
   "metadata": {},
   "source": [
    "### Conclusion: we can see these three models LGBMClassifier,RidgeClassifier and BernoulliNB has the best accuracy but in this project we want to train logistic regression,SVM,decision tree and KNN model and compare these models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d869e320",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfb055cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameteres for Logistic regression are:{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'} and best accuracy score is 0.8339285714285714\n"
     ]
    }
   ],
   "source": [
    "#create a logistic regression object\n",
    "classifier_lr = LogisticRegression()\n",
    "#define parameters for logistic regression grid search\n",
    "params = {\n",
    "    'C':[0.01,0.1,1],\n",
    "    'penalty':['l2'],\n",
    "    'solver':['lbfgs']\n",
    "}\n",
    "#create a logistic regression grid search object\n",
    "logreg_cv = GridSearchCV(classifier_lr,\n",
    "                  param_grid=params,cv=10,scoring='accuracy')\n",
    "#train grid search object\n",
    "logreg_cv.fit(X_train,Y_train)\n",
    "#print best parameters and score for logistic regression\n",
    "print('The best parameteres for Logistic regression are:{x} and best accuracy score is {y}'.format(x=logreg_cv.best_params_,y=logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d8468a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "[[ 3  3]\n",
      " [ 0 12]]\n"
     ]
    }
   ],
   "source": [
    "#create svm classifier object with best parameters\n",
    "classifier_lr=LogisticRegression(C=0.1,penalty='l2',solver='lbfgs')\n",
    "#train classifier\n",
    "classifier_lr.fit(X_train,Y_train)\n",
    "#predict values for test set\n",
    "Y_predict = classifier_lr.predict(X_test)\n",
    "# find and print accuracy in test set\n",
    "logisticregression_accuracy = accuracy_score(Y_test,Y_predict)\n",
    "print(logisticregression_accuracy)\n",
    "#find and print confusion matrix\n",
    "logisticregression_matrix=confusion_matrix(Y_test,Y_predict)\n",
    "print(logisticregression_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e45ed9",
   "metadata": {},
   "source": [
    "# Support Vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83f72dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameteres for SVM are:{'C': 1.0, 'gamma': 0.03162277660168379, 'kernel': 'sigmoid'} and best accuracy score is 0.8482142857142858\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create a svm object\n",
    "svm_classifier = SVC()\n",
    "#create a parameters for SVM grid search\n",
    "params = {\n",
    "    'kernel':('linear','rbf','poly','sigmoid'),\n",
    "    'C':np.logspace(-3,3,5),\n",
    "    'gamma':np.logspace(-3,3,5)\n",
    "}\n",
    "# create a svm grid search object\n",
    "svm_cv = GridSearchCV(svm_classifier,\n",
    "                     param_grid=params,\n",
    "                     cv=10,\n",
    "                     )\n",
    "#train grid search object\n",
    "svm_cv.fit(X_train,Y_train)\n",
    "#find the best parameters and score\n",
    "print('The best parameteres for SVM are:{x} and best accuracy score is {y}'.format(x=svm_cv.best_params_,y=svm_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54990b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "[[ 3  3]\n",
      " [ 0 12]]\n"
     ]
    }
   ],
   "source": [
    "#create svm object with best parameters\n",
    "svm_classifier = SVC(C=1.0,gamma=0.03162277660168379,kernel='sigmoid')\n",
    "#train classifier\n",
    "svm_classifier.fit(X_train,Y_train)\n",
    "#predict values of test set\n",
    "Y_predict=svm_classifier.predict(X_test)\n",
    "#print accuracy\n",
    "svm_accuracy = accuracy_score(Y_test,Y_predict)\n",
    "print(svm_accuracy)\n",
    "#print confusion matrix\n",
    "svm_matrix = confusion_matrix(Y_test,Y_predict)\n",
    "print(svm_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb4c72e",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26a79233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameteres for SVM are:{'criterion': 'gini', 'max_depth': 4, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'} and best accuracy score is 0.8607142857142858\n"
     ]
    }
   ],
   "source": [
    "#create a object for decision tree \n",
    "decisiontree_classifier= DecisionTreeClassifier()\n",
    "#define parameters for decision tree grid search\n",
    "params={\n",
    "    'criterion':['gini','entropy'],\n",
    "    'splitter':['best','random'],\n",
    "    'max_depth':[2*n for n in range(1,10)],\n",
    "    'max_features':['auto','sqrt'],\n",
    "    'min_samples_leaf':[1,2,4],\n",
    "    'min_samples_split':[2,5,10]\n",
    "}\n",
    "#create a decision tree grid search object\n",
    "tree_cv = GridSearchCV(decisiontree_classifier,\n",
    "                      param_grid=params,\n",
    "                      cv=10,\n",
    "                      scoring='accuracy')\n",
    "#train grid search object with training set\n",
    "tree_cv.fit(X_train,Y_train)\n",
    "#print the best parameters and score\n",
    "print('The best parameteres for Decision Tree are:{x} and best accuracy score is {y}'.format(x=tree_cv.best_params_,y=tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83f451a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "[[ 3  3]\n",
      " [ 0 12]]\n"
     ]
    }
   ],
   "source": [
    "#create a decision tree classifier with best parameters\n",
    "decisiontree_classifier=DecisionTreeClassifier(criterion='gini',max_depth=4,max_features='auto',min_samples_leaf=2,min_samples_split=5,splitter='best')\n",
    "#train decision tree classifer\n",
    "decisiontree_classifier.fit(X_train,Y_train)\n",
    "#predict values for test set\n",
    "Y_predict = decisiontree_classifier.predict(X_test)\n",
    "#find and print accuracy \n",
    "decisiontree_accuracy = accuracy_score(Y_test,Y_predict)\n",
    "print(decisiontree_accuracy)\n",
    "#find and print confusion matrix\n",
    "decisiontree_matrix =confusion_matrix(Y_test,Y_predict)\n",
    "print(decisiontree_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea20e441",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0881e9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "910a97ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameteres for KNN are:{'algorithm': 'auto', 'n_neighbors': 8, 'p': 1} and best accuracy score is 0.8321428571428571\n"
     ]
    }
   ],
   "source": [
    "#create a KNN classifier object\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "#define parameters for grid search\n",
    "params={\n",
    "    'n_neighbors':[1,2,3,4,5,6,7,8,9,10],\n",
    "    'algorithm':['auto','ball_tree','kd_tree','brute'],\n",
    "    'p':[1,2]\n",
    "}\n",
    "#create a knn grid search object\n",
    "knn_cv=GridSearchCV(knn_classifier,\n",
    "                   param_grid=params,\n",
    "                   cv=10)\n",
    "#train grid search object\n",
    "knn_cv.fit(X_train,Y_train)\n",
    "#print best parameters and best score\n",
    "print('The best parameteres for KNN are:{x} and best accuracy score is {y}'.format(x=knn_cv.best_params_,y=knn_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b1906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a knn classifier object with best parameters\n",
    "knn_classifier = KNeighborsClassifier(algorithm='auto',n_neighbors=8,p=1)\n",
    "#train "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
